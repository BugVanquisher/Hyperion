input {
  beats {
    port => 5044
  }
}

filter {
  # Parse Docker container logs
  if [container][name] {
    mutate {
      add_field => { "service" => "%{[container][name]}" }
    }
  }

  # Parse JSON logs from FastAPI application
  if [container][name] == "hyperion-app" or [container][name] == "hyperion-app-gpu" {
    # Try to parse JSON logs
    json {
      source => "message"
      target => "app"
      skip_on_invalid_json => true
    }

    # Parse standard Python logs
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{WORD:logger_name} - %{LOGLEVEL:log_level} - %{GREEDYDATA:log_message}"
      }
      tag_on_failure => ["_grokparsefailure_python_log"]
    }

    # Extract GPU metrics from logs
    if [log_message] =~ /GPU/ {
      grok {
        match => {
          "log_message" => "GPU memory allocated: %{NUMBER:gpu_memory_allocated:float}GB"
        }
        tag_on_failure => ["_grokparsefailure_gpu"]
      }

      grok {
        match => {
          "log_message" => "GPU memory reserved: %{NUMBER:gpu_memory_reserved:float}GB"
        }
        tag_on_failure => ["_grokparsefailure_gpu"]
      }

      grok {
        match => {
          "log_message" => "Using CUDA device: %{GREEDYDATA:gpu_name}"
        }
        tag_on_failure => ["_grokparsefailure_gpu"]
      }

      mutate {
        add_tag => ["gpu_metrics"]
      }
    }

    # Extract batch processing metrics
    if [log_message] =~ /batch/ {
      grok {
        match => {
          "log_message" => "Processing batch of %{NUMBER:batch_size:int} requests"
        }
        tag_on_failure => ["_grokparsefailure_batch"]
      }

      grok {
        match => {
          "log_message" => "Batch completed in %{NUMBER:batch_duration:float}s"
        }
        tag_on_failure => ["_grokparsefailure_batch"]
      }

      grok {
        match => {
          "log_message" => "avg_batch_time=%{NUMBER:avg_batch_time:float}s"
        }
        tag_on_failure => ["_grokparsefailure_batch"]
      }

      mutate {
        add_tag => ["batch_metrics"]
      }
    }

    # Extract model inference metrics
    if [log_message] =~ /Model loaded successfully/ {
      grok {
        match => {
          "log_message" => "Model loaded successfully on %{WORD:device_type}"
        }
        tag_on_failure => ["_grokparsefailure_model"]
      }

      mutate {
        add_tag => ["model_lifecycle"]
      }
    }

    # Extract cache operations
    if [log_message] =~ /Cache/ {
      grok {
        match => {
          "log_message" => "Cache %{WORD:cache_operation} for prompt: '%{DATA:prompt_preview}'"
        }
        tag_on_failure => ["_grokparsefailure_cache"]
      }

      mutate {
        add_tag => ["cache_operations"]
      }
    }

    # Extract HTTP request metrics
    if [log_message] =~ /INFO:.*uvicorn/ {
      grok {
        match => {
          "log_message" => "%{IP:client_ip} - \"%{WORD:http_method} %{URIPATHPARAM:http_path} HTTP/%{NUMBER:http_version}\" %{INT:http_status:int}"
        }
        tag_on_failure => ["_grokparsefailure_http"]
      }

      mutate {
        add_tag => ["http_requests"]
      }
    }

    # Add timestamp from log if available
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601" ]
        target => "@timestamp"
      }
    }

    # Add ML-specific fields
    mutate {
      add_field => { "component" => "ml_inference" }
      add_field => { "environment" => "development" }
      add_field => { "service_version" => "2.0" }
    }
  }

  # Process Prometheus/Grafana logs
  if [container][name] == "hyperion-prometheus" {
    mutate {
      add_field => { "component" => "monitoring" }
      add_tag => ["prometheus"]
    }
  }

  if [container][name] == "hyperion-grafana" {
    mutate {
      add_field => { "component" => "visualization" }
      add_tag => ["grafana"]
    }
  }

  # Process Jaeger logs
  if [container][name] =~ /jaeger/ {
    mutate {
      add_field => { "component" => "tracing" }
      add_tag => ["jaeger"]
    }
  }

  # Process Redis logs
  if [container][name] =~ /redis/ {
    mutate {
      add_field => { "component" => "cache" }
      add_tag => ["redis"]
    }
  }

  # Clean up fields
  mutate {
    remove_field => [ "agent", "ecs", "input", "log" ]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "hyperion-logs-%{+YYYY.MM.dd}"
    template_name => "hyperion"
    template_pattern => "hyperion-*"
    template => '{
      "index_patterns": ["hyperion-*"],
      "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0,
        "index.refresh_interval": "5s"
      },
      "mappings": {
        "properties": {
          "@timestamp": { "type": "date" },
          "message": { "type": "text" },
          "service": { "type": "keyword" },
          "component": { "type": "keyword" },
          "log_level": { "type": "keyword" },
          "batch_size": { "type": "integer" },
          "batch_duration": { "type": "float" },
          "gpu_memory_allocated": { "type": "float" },
          "gpu_memory_reserved": { "type": "float" },
          "gpu_name": { "type": "keyword" },
          "device_type": { "type": "keyword" },
          "http_status": { "type": "integer" },
          "http_method": { "type": "keyword" },
          "http_path": { "type": "keyword" },
          "client_ip": { "type": "ip" }
        }
      }
    }'
  }

  # Debug output (comment out in production)
  stdout {
    codec => rubydebug
  }
}